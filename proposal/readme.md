# task

Proposal

LIU part
• Title: A Deep Learning Based Collaborative Filtering Model For Recommander System

• Motivation. What will you focus on and why the problem is important? 
	- Collaborative filtering in recommander system
		Defination
		Task that CF wants to address	
	- Matrix factorization
		Introduction
		Characteristics:
			matrix modelling -> very suitable for applying deep learning to fit matrix
			Original MF makes use of only rating data -> combine additional data to improve
	- Deep learning
		使用 DMF 论文中阐述的 DNN fit 进 MF 的好处

• Background. What are the existing work (from others) concerning the topic?
	DMF: https://zhuanlan.zhihu.com/p/474085561
	MF: https://datajobs.com/data-science-repo/Recommender-Systems-[Netflix].pdf
	Temporal Dynamics: https://dl.acm.org/doi/pdf/10.1145/1557019.1557072

	进阶阐述这些 previous work 给我们的指导价值

LIN part
• Contents. What you plan to discuss in the final report. 
	Define the objectives:

		1. Implement a DNN-based MF model for top-N recommandation
		2. Integrate additional temporal and social data to produce an enhanced model
	Methodology: 
	Experiment: experiment and compare the performance
	Conclusion & future work

• Plans. How you will schedule your time to make progress? 
• Teamwork. How each individual will contribute to the group project.

# content

Title. What is the title of your project?
• Motivation. What will you focus on and why the problem is important?
• Background. What are the existing work (from others) concerning the topic?
• Contents. What you plan to discuss in the final report.
• Plans. How you will schedule your time to make progress?
• Teamwork. How each individual will contribute to the group project?

# data

https://www.kaggle.com/datasets/yelp-dataset/yelp-dataset)

# requirement

§ Image (e.g., product image)
§ Text (e.g., review text)
§ Network (e.g., user social network and similar product network)
§ Spatio-temporal (e.g., review time and business location)
§ Users’ ratings on products/businesses



The Transformer is a deep learning architecture comprising an encoder and a decoder. It leverages a "self-attention" mechanism to grasp connections between words positioned variably within a sentence.

还是说用transformer basesd去搞

